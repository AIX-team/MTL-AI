import time
import os
import requests
import datetime
import tiktoken
from math import ceil
from langdetect import detect
from dotenv import load_dotenv
from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound
from bs4 import BeautifulSoup
import openai
from googleapiclient.discovery import build
import googlemaps
from typing import List, Dict, Tuple, Any
from models.youtube_schemas import YouTubeResponse, VideoInfo, PlaceInfo, PlacePhoto
from repository.youtube_repository import YouTubeRepository
from langchain.schema import Document

from ai_api.youtube_subtitle import (
    get_video_info, process_link, split_text, summarize_text,
    extract_place_names, search_place_details, get_place_photo_google
)

# í™˜ê²½ ë³€ìˆ˜ ë° ìƒìˆ˜ ì„¤ì •
load_dotenv(dotenv_path=".env")

# API í‚¤ ì„¤ì •
openai.api_key = os.getenv("OPENAI_API_KEY")
GEOCODING_API_KEY = os.getenv("GOOGLE_GEOCODING_API_KEY")
GOOGLE_PLACES_API_KEY = os.getenv("GOOGLE_PLACES_API_KEY")

# ìƒìˆ˜ ì„¤ì •
MAX_URLS = 5
CHUNK_SIZE = 2048
MODEL = "gpt-4o-mini"
FINAL_SUMMARY_MAX_TOKENS = 1500

class YouTubeService:
    """ë©”ì¸ YouTube ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.repository = YouTubeRepository()
        self.subtitle_service = YouTubeSubtitleService()
        self.text_service = TextProcessingService()
        self.place_service = PlaceService()

    def process_urls(self, urls: List[str]) -> YouTubeResponse:
        try:
            start_time = time.time()
            all_text = ""
            video_infos = []
            
            # 1. URL ì²˜ë¦¬ ë° í…ìŠ¤íŠ¸ ì¶”ì¶œ
            for idx, url in enumerate(urls, 1):
                print(f"\nURL {idx}/{len(urls)} ì²˜ë¦¬ ì¤‘: {url}")
                video_title, channel_name = self.subtitle_service.get_video_info(url)
                if video_title and channel_name:
                    video_infos.append(VideoInfo(url=url, title=video_title, channel=channel_name))
                text = self.subtitle_service.process_link(url)
                all_text += f"\n\n--- URL {idx} ë‚´ìš© ---\n{text}"

            # 2. í…ìŠ¤íŠ¸ ë¶„í•  ë° ìš”ì•½
            chunks = self.text_service.split_text(all_text)
            summary = self.text_service.summarize_text(chunks)
            
            # 3. ì¥ì†Œ ì¶”ì¶œ ë° ì •ë³´ ìˆ˜ì§‘
            place_names = self.place_service.extract_place_names(summary)
            print(f"ì¶”ì¶œëœ ì¥ì†Œ: {place_names}")
            
            # 4. ì¥ì†Œ ì •ë³´ ìˆ˜ì§‘
            place_details = []
            for place_name in place_names:
                try:
                    # Google Places APIë¡œ ì¥ì†Œ ì •ë³´ ê²€ìƒ‰
                    place_info = self.place_service.search_place_details(place_name)
                    
                    # ì¥ì†Œ ì„¤ëª… ì¶”ì¶œ (ìœ íŠœë²„ ë¦¬ë·°)
                    description = self._extract_place_description(summary, place_name)
                    
                    if not place_info:
                        # êµ¬ê¸€ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°
                        place_details.append(PlaceInfo(
                            name=place_name,
                            description=description,
                            google_info={}  # ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¡œ ì„¤ì •
                        ))
                        continue
                    
                    # ì‚¬ì§„ URL ê°€ì ¸ì˜¤ê¸°
                    photo_url = self.place_service.get_place_photo_google(place_name)
                    photos = [PlacePhoto(url=photo_url)] if photo_url else []
                    
                    # PlaceInfo ê°ì²´ ìƒì„±
                    place_details.append(PlaceInfo(
                        name=place_name,
                        description=description,
                        formatted_address=place_info.get('formatted_address'),
                        rating=place_info.get('rating'),
                        phone=place_info.get('formatted_phone_number'),
                        website=place_info.get('website'),
                        price_level=place_info.get('price_level'),
                        opening_hours=place_info.get('opening_hours', []),
                        photos=photos,
                        best_review=place_info.get('best_review'),
                        google_info=place_info  # ì „ì²´ êµ¬ê¸€ ì •ë³´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ì €ì¥
                    ))
                    print(f"ì¥ì†Œ ì •ë³´ ì¶”ê°€ ì™„ë£Œ: {place_name}")
                except Exception as e:
                    print(f"ì¥ì†Œ ì •ë³´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({place_name}): {str(e)}")
                    # ì—ëŸ¬ê°€ ë°œìƒí•œ ê²½ìš°
                    place_details.append(PlaceInfo(
                        name=place_name,
                        description=description,
                        google_info={}  # ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¡œ ì„¤ì •
                    ))
                    continue

            # 5. ìµœì¢… ê²°ê³¼ ìƒì„±
            processing_time = time.time() - start_time
            final_result = self._format_final_result(
                video_infos=video_infos,
                final_summary=summary,
                place_details=place_details,
                processing_time=processing_time,
                urls=urls
            )
            
            # 6. ê²°ê³¼ ì €ì¥
            self.repository.save_final_summary(final_result)
            
            return YouTubeResponse(
                final_summary=final_result,
                video_infos=video_infos,
                processing_time_seconds=processing_time,
                place_details=place_details
            )
            
        except Exception as e:
            raise Exception(f"URL ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    def _extract_place_description(self, summary: str, place_name: str) -> str:
        """ìš”ì•½ í…ìŠ¤íŠ¸ì—ì„œ íŠ¹ì • ì¥ì†Œì— ëŒ€í•œ ì„¤ëª…ì„ ì¶”ì¶œ"""
        try:
            # ì¥ì†Œ ì´ë¦„ì„ í¬í•¨í•˜ëŠ” ë¬¸ì¥ë“¤ì„ ì°¾ìŒ
            sentences = summary.split('.')
            relevant_sentences = [s.strip() for s in sentences if place_name.lower() in s.lower()]
            
            if relevant_sentences:
                return ' '.join(relevant_sentences)
            return "ì¥ì†Œ ì„¤ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        except Exception:
            return "ì¥ì†Œ ì„¤ëª… ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    def _format_final_result(self, video_infos: List[VideoInfo], final_summary: str, 
                           place_details: List[PlaceInfo], processing_time: float,
                           urls: List[str]) -> str:
        """ìµœì¢… ê²°ê³¼ ë¬¸ìì—´ì„ í¬ë§·íŒ…í•˜ëŠ” ë©”ì„œë“œ"""
        
        # 1. ê¸°ë³¸ ì •ë³´ í—¤ë”
        final_result = f"""
=== ì—¬í–‰ ì •ë³´ ìš”ì•½ ===
ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ

ë¶„ì„í•œ ì˜ìƒ:
{'='*50}"""
        
        # 2. ë¹„ë””ì˜¤ ì •ë³´
        if video_infos:
            for info in video_infos:
                final_result += f"""
ì œëª©: {info.title}
ì±„ë„: {info.channel}
URL: {info.url}"""
        else:
            final_result += f"\nURL: {chr(10).join(urls)}"
        
        final_result += f"\n{'='*50}\n\n=== ì¥ì†Œë³„ ìƒì„¸ ì •ë³´ ===\n"

        # 3. ì¥ì†Œë³„ ì •ë³´
        for idx, place in enumerate(place_details, 1):
            final_result += f"""
{idx}. {place.name}
{'='*50}

[ìœ íŠœë²„ì˜ ë¦¬ë·°]
ì¥ì†Œì„¤ëª…: {place.description or 'ì¥ì†Œ ì„¤ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}
"""
            # êµ¬ê¸€ ì¥ì†Œ ì •ë³´ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì¶”ê°€
            if place.google_info:
                final_result += f"""
[êµ¬ê¸€ ì¥ì†Œ ì •ë³´]
ğŸ  ì£¼ì†Œ: {place.formatted_address or 'ì •ë³´ ì—†ìŒ'}
â­ í‰ì : {place.rating or 'None'}
ğŸ“ ì „í™”: {place.phone or 'None'}
ğŸŒ ì›¹ì‚¬ì´íŠ¸: {place.website or 'None'}
ğŸ’° ê°€ê²©ëŒ€: {'â‚©' * place.price_level if place.price_level else 'ì •ë³´ ì—†ìŒ'}
â° ì˜ì—…ì‹œê°„:
{chr(10).join(place.opening_hours if place.opening_hours else ['ì •ë³´ ì—†ìŒ'])}

[ì‚¬ì§„ ë° ë¦¬ë·°]"""
                
                if place.photos:
                    for photo_idx, photo in enumerate(place.photos, 1):
                        final_result += f"""
ğŸ“¸ ì‚¬ì§„ {photo_idx}: {photo.url}"""
                
                final_result += f"""
â­ ë² ìŠ¤íŠ¸ ë¦¬ë·°: {place.best_review or 'ë¦¬ë·° ì—†ìŒ'}"""
            
            final_result += f"\n{'='*50}"
        
        return final_result

    def search_content(self, query: str) -> List[Dict]:
        """ë²¡í„° DBì—ì„œ ì½˜í…ì¸  ê²€ìƒ‰"""
        try:
            results = self.repository.query_vectordb(query)
            filtered_results = []

            for doc in results:
                if isinstance(doc, Document) and hasattr(doc, "metadata") and hasattr(doc, "page_content"):
                    filtered_results.append({
                        'content': doc.page_content,
                        'metadata': doc.metadata
                    })
                else:
                    print(f"âš ï¸ ì˜ëª»ëœ ë°ì´í„° íƒ€ì… ê°ì§€: {type(doc)} - {doc}")

            return filtered_results
        except Exception as e:
            raise Exception(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

class YouTubeSubtitleService:
    """YouTube ìë§‰ ë° ë¹„ë””ì˜¤ ì •ë³´ ì²˜ë¦¬ ì„œë¹„ìŠ¤"""
    
    @staticmethod
    def get_video_info(video_url: str) -> Tuple[str, str]:
        try:
            video_id = video_url.split("v=")[-1].split("&")[0]
            api_url = f"https://noembed.com/embed?url=https://www.youtube.com/watch?v={video_id}"
            response = requests.get(api_url)
            if response.status_code == 200:
                data = response.json()
                title = data.get('title')
                author_name = data.get('author_name')
                print(f"[get_video_info] ì œëª©: {title}, ì±„ë„: {author_name}")
                return title, author_name
            print(f"[get_video_info] API ì‘ë‹µ ìƒíƒœ ì½”ë“œ: {response.status_code}")
            return None, None
        except Exception as e:
            print(f"ì˜ìƒ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
            return None, None

    @staticmethod
    def process_link(url: str) -> str:
        link_type = YouTubeSubtitleService._detect_link_type(url)
        print(f"[process_link] ë§í¬ ìœ í˜• ê°ì§€: {link_type}")
        
        if link_type == "youtube":
            text = YouTubeSubtitleService._get_youtube_transcript(url)
        elif link_type == "text_file":
            text = YouTubeSubtitleService._get_text_from_file(url)
        else:
            text = YouTubeSubtitleService._get_text_from_webpage(url)
        
        print(f"[process_link] ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)}")
        return text

    @staticmethod
    def _detect_link_type(url: str) -> str:
        if "youtube.com" in url or "youtu.be" in url:
            return "youtube"
        elif url.endswith(".txt"):
            return "text_file"
        elif url.startswith("http"):
            return "webpage"
        else:
            return "unknown"

    @staticmethod
    def _format_timestamp(seconds: float) -> str:
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        return f"{hours:02d}:{minutes:02d}:{secs:02d}"

    @staticmethod
    def _get_youtube_transcript(video_url: str) -> str:
        video_id = video_url.split("v=")[-1].split("&")[0]
        print(f"[get_youtube_transcript] ë¹„ë””ì˜¤ ID: {video_id}")
        
        try:
            transcripts = YouTubeTranscriptApi.list_transcripts(video_id)
            
            # 1. ë¨¼ì € í•œêµ­ì–´ ìë§‰ ì‹œë„
            try:
                transcript = transcripts.find_transcript(['ko'])
                transcript_text = "\n".join([f"[{YouTubeSubtitleService._format_timestamp(entry['start'])}] {entry['text']}" for entry in transcript.fetch()])
                print(f"[get_youtube_transcript] í•œêµ­ì–´ ìë§‰ ì¶”ì¶œ ì™„ë£Œ. ê¸¸ì´: {len(transcript_text)}")
                return transcript_text
            except (TranscriptsDisabled, NoTranscriptFound):
                print("[get_youtube_transcript] í•œêµ­ì–´ ìë§‰ ì—†ìŒ.")

            # 2. ì˜ì–´ ìë§‰ ì‹œë„
            try:
                transcript = transcripts.find_transcript(['en'])
                transcript_text = "\n".join([f"[{YouTubeSubtitleService._format_timestamp(entry['start'])}] {entry['text']}" for entry in transcript.fetch()])
                print(f"[get_youtube_transcript] ì˜ì–´ ìë§‰ ì¶”ì¶œ ì™„ë£Œ. ê¸¸ì´: {len(transcript_text)}")
                return transcript_text
            except (TranscriptsDisabled, NoTranscriptFound):
                print("[get_youtube_transcript] ì˜ì–´ ìë§‰ ì—†ìŒ.")

            # 3. ì‚¬ìš© ê°€ëŠ¥í•œ ì²« ë²ˆì§¸ ìë§‰ ì‹œë„
            try:
                transcript = transcripts.find_generated_transcript()
                transcript_text = "\n".join([f"[{YouTubeSubtitleService._format_timestamp(entry['start'])}] {entry['text']}" for entry in transcript.fetch()])
                print(f"[get_youtube_transcript] ìƒì„±ëœ ìë§‰ ì¶”ì¶œ ì™„ë£Œ. ê¸¸ì´: {len(transcript_text)}")
                return transcript_text
            except Exception as e:
                print(f"[get_youtube_transcript] ìƒì„±ëœ ìë§‰ ì¶”ì¶œ ì‹¤íŒ¨: {e}")

            raise ValueError("ì‚¬ìš© ê°€ëŠ¥í•œ ìë§‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        except Exception as e:
            raise ValueError(f"ë¹„ë””ì˜¤ {video_id}ì˜ ìë§‰ì„ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")

    @staticmethod
    def _get_text_from_file(url: str) -> str:
        try:
            response = requests.get(url)
            response.raise_for_status()
            text = response.text.strip()
            print(f"[get_text_from_file] í…ìŠ¤íŠ¸ íŒŒì¼ ì¶”ì¶œ ì™„ë£Œ. ê¸¸ì´: {len(text)}")
            return text
        except Exception as e:
            raise ValueError(f"í…ìŠ¤íŠ¸ íŒŒì¼ ë‚´ìš©ì„ ê°€ì ¸ì˜¤ëŠ”ë° ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

    @staticmethod
    def _get_text_from_webpage(url: str) -> str:
        try:
            response = requests.get(url)
            response.raise_for_status()
            soup = BeautifulSoup(response.content, "html.parser")
            text = soup.get_text(separator="\n").strip()
            text = text[:10000]  # ê¸¸ì´ ì œí•œ 10000ì
            print(f"[get_text_from_webpage] ì›¹í˜ì´ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ. ê¸¸ì´: {len(text)}")
            return text
        except Exception as e:
            raise ValueError(f"ì›¹í˜ì´ì§€ ë‚´ìš©ì„ ê°€ì ¸ì˜¤ëŠ”ë° ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

class TextProcessingService:
    """í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì„œë¹„ìŠ¤"""
    
    @staticmethod
    def split_text(text: str, max_chunk_size: int = CHUNK_SIZE) -> List[str]:
        words = text.split()
        total_words = len(words)
        num_chunks = ceil(total_words / (max_chunk_size // 5))
        chunks = []
        for i in range(num_chunks):
            start = i * (max_chunk_size // 5)
            end = start + (max_chunk_size // 5)
            chunk = ' '.join(words[start:end])
            chunks.append(chunk)
        print(f"[split_text] ì´ ë‹¨ì–´ ìˆ˜: {total_words}, ì²­í¬ ìˆ˜: {num_chunks}")
        return chunks

    @staticmethod
    def summarize_text(transcript_chunks: List[str], model: str = MODEL) -> str:
        summaries = []
        for idx, chunk in enumerate(transcript_chunks):
            prompt = TextProcessingService._generate_prompt(chunk)
            try:
                response = openai.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system", "content": "You are a travel expert who provides detailed recommendations for places to visit, foods to eat, precautions, and suggestions based on transcripts."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.1,
                    max_tokens=1500
                )
                summary = response.choices[0].message.content
                summaries.append(summary)
                print(f"ì²­í¬ {idx+1}/{len(transcript_chunks)} ìš”ì•½ ì™„ë£Œ.")
                print(f"[ì²­í¬ {idx+1} ìš”ì•½ ë‚´ìš© ì¼ë¶€]")
                print(summary[:500])
            except Exception as e:
                raise ValueError(f"ìš”ì•½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        # ê°œë³„ ìš”ì•½ì„ í•©ì³ì„œ ìµœì¢… ìš”ì•½
        combined_summaries = "\n".join(summaries)
        final_prompt = f"""
ì•„ë˜ëŠ” ì—¬ëŸ¬ ì²­í¬ë¡œ ë‚˜ë‰œ ìš”ì•½ì…ë‹ˆë‹¤. ì´ ìš”ì•½ë“¤ì„ í†µí•©í•˜ì—¬ ë‹¤ìŒì˜ í˜•ì‹ìœ¼ë¡œ ìµœì¢… ìš”ì•½ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”. ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ì„ ë”°ë¥´ê³ , ë¹ ì§€ëŠ” ë‚´ìš© ì—†ì´ ëª¨ë“  ì •ë³´ë¥¼ í¬í•¨í•´ ì£¼ì„¸ìš”.
**ìš”êµ¬ ì‚¬í•­:**
1. ì¥ì†Œ, ìŒì‹, ìœ ì˜ ì‚¬í•­, ì¶”ì²œ ì‚¬í•­ ë“± ê°ê°ì˜ ì •ë³´ë¥¼ ì„¸ë¶€ì ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
2. ë§Œì•½ í•´ë‹¹ ì¥ì†Œì—ì„œ ë¨¹ì€ ìŒì‹, ìœ ì˜ ì‚¬í•­, ì¶”ì²œ ì‚¬í•­ì´ ì—†ë‹¤ë©´ ì‘ì„±í•˜ì§€ ì•Šê³  ë„˜ì–´ê°€ë„ ë©ë‹ˆë‹¤.
3. ë°©ë¬¸í•œ ì¥ì†Œê°€ ì—†ê±°ë‚˜ ìœ ì˜ ì‚¬í•­ë§Œ ìˆì„ ë•Œ, ìœ ì˜ ì‚¬í•­ ì„¹ì…˜ì— ëª¨ì•„ì£¼ì„¸ìš”.
4. ì¶”ì²œ ì‚¬í•­ë§Œ ìˆëŠ” ê²ƒë“¤ì€ ì¶”ì²œ ì‚¬í•­ ì„¹ì…˜ì— ëª¨ì•„ì£¼ì„¸ìš”.
5. ê°€ëŠ¥í•œ ì¥ì†Œ ì´ë¦„ì„ ì•Œê³  ìˆë‹¤ë©´ ì‹¤ì œ ì£¼ì†Œë¥¼ í¬í•¨í•´ ì£¼ì„¸ìš”.
**ê²°ê³¼ í˜•ì‹:**

ê²°ê³¼ëŠ” ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”
ì•„ë˜ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤. 

ë°©ë¬¸í•œ ì¥ì†Œ: ìŠ¤ë¯¸ë‹¤ íƒ€ì›Œ (ì£¼ì†Œ) íƒ€ì„ìŠ¤íƒ¬í”„: [HH:MM:SS]
- ì¥ì†Œì„¤ëª…: [ìœ íŠœë²„ì˜ ì„¤ëª…] ë„ì¿„ ìŠ¤ì¹´ì´íŠ¸ë¦¬ë¥¼ ëŒ€í‘œí•˜ëŠ” ëœë“œë§ˆí¬ë¡œ, ì „ë§ëŒ€ì—ì„œ ë„ì¿„ ì‹œë‚´ë¥¼ í•œëˆˆì— ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìœ íŠœë²„ê°€ ë°©ë¬¸í–ˆì„ ë•ŒëŠ” ë‚ ì”¨ê°€ ì¢‹ì•„ì„œ í›„ì§€ì‚°ê¹Œì§€ ë³´ì˜€ê³ , ì•¼ê²½ì´ íŠ¹íˆ ì•„ë¦„ë‹¤ì› ë‹¤ê³  í•©ë‹ˆë‹¤.
- ë¨¹ì€ ìŒì‹: ë¼ë©˜ ì´ì¹˜ë€
    - ì„¤ëª…: ì§„í•œ êµ­ë¬¼ê³¼ ì«„ê¹ƒí•œ ë©´ë°œë¡œ ìœ ëª…í•œ ë¼ë©˜ ì²´ì¸ì ìœ¼ë¡œ, ê°œì¸ì‹¤ì—ì„œ í¸ì•ˆí•˜ê²Œ ì‹ì‚¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ìœ ì˜ ì‚¬í•­: í˜¼ì¡í•œ ì‹œê°„ëŒ€ í”¼í•˜ê¸°
    - ì„¤ëª…: ê´€ê´‘ì§€ ì£¼ë³€ì€ íŠ¹íˆ ì£¼ë§ê³¼ íœ´ì¼ì— ë§¤ìš° í˜¼ì¡í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ê°€ëŠ¥í•œ í‰ì¼ì´ë‚˜ ì´ë¥¸ ì‹œê°„ì— ë°©ë¬¸í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
- ì¶”ì²œ ì‚¬í•­: ìŠ¤ì¹´ì´ íŠ¸ë¦¬ ì „ë§ëŒ€ ë°©ë¬¸
    - ì„¤ëª…: ë„ì¿„ì˜ ì•„ë¦„ë‹¤ìš´ ì•¼ê²½ì„ ê°ìƒí•  ìˆ˜ ìˆìœ¼ë©°, ì‚¬ì§„ ì´¬ì˜ í•˜ê¸°ì— ìµœì ì˜ ì¥ì†Œì…ë‹ˆë‹¤.

ë°©ë¬¸í•œ ì¥ì†Œ: ìœ ë‹ˆë²„ì…œ ìŠ¤íŠœë””ì˜¤ ì¼ë³¸ (ì£¼ì†Œ) íƒ€ì„ìŠ¤íƒ¬í”„: [HH:MM:SS]
- ì¥ì†Œì„¤ëª…: [ìœ íŠœë²„ì˜ ì„¤ëª…] ìœ íŠœë²„ê°€ ë°©ë¬¸í–ˆì„ ë•ŒëŠ” í‰ì¼ì„ì—ë„ ì‚¬ëŒì´ ë§ì•˜ì§€ë§Œ, ì‹±ê¸€ë¼ì´ë”ë¥¼ ì´ìš©í•´ì„œ ëŒ€ê¸° ì‹œê°„ì„ ë§ì´ ì¤„ì¼ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. íŠ¹íˆ í•´ë¦¬í¬í„° êµ¬ì—­ì˜ ë¶„ìœ„ê¸°ê°€ ì‹¤ì œ ì˜í™”ì˜ í•œ ì¥ë©´ì— ë“¤ì–´ì˜¨ ê²ƒ ê°™ì•˜ê³ , ë²„í„°ë§¥ì£¼ë„ ë§›ìˆì—ˆë‹¤ê³  í•©ë‹ˆë‹¤.
- ìœ ì˜ ì‚¬í•­: ì§§ì€ ì˜· ì°©ìš© 
    - ì„¤ëª…: íŒ€ë© í”Œë˜ë‹›ì˜ ì¼ë¶€ êµ¬ì—­ì—ì„œëŠ” ë¬¼ì´ ë†’ê³  ê±°ìš¸ì´ ìˆìœ¼ë¯€ë¡œ, ì§§ì€ ì˜·ì„ ì…ëŠ” ê²ƒì´ ì¢‹ë‹¤.

**ìš”ì•½ ì²­í¬:**
{combined_summaries}

**ìµœì¢… ìš”ì•½:**
"""
        try:
            final_response = openai.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "You are an expert summary writer who strictly adheres to the provided format."},
                    {"role": "user", "content": final_prompt}
                ],
                temperature=0.1,
                max_tokens=4096
            )
            final_summary = final_response.choices[0].message.content
            print("\n[ìµœì¢… ìš”ì•½ ë‚´ìš© ì¼ë¶€]")
            print(final_summary[:1000])
            return final_summary
        except Exception as e:
            raise ValueError(f"ìµœì¢… ìš”ì•½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    @staticmethod
    def _generate_prompt(transcript_chunk: str) -> str:
        language = detect(transcript_chunk)
        if language != 'ko':
            translation_instruction = "ì´ í…ìŠ¤íŠ¸ëŠ” í•œêµ­ì–´ê°€ ì•„ë‹™ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ ì£¼ì„¸ìš”.\n\n"
        else:
            translation_instruction = ""

        base_prompt = f"""
{translation_instruction}
ì•„ë˜ëŠ” ì—¬í–‰ ìœ íŠœë²„ê°€ ì´¬ì˜í•œ ì˜ìƒì˜ ìë§‰ì…ë‹ˆë‹¤. ì´ ìë§‰ì—ì„œ ë°©ë¬¸í•œ ì¥ì†Œ, ë¨¹ì€ ìŒì‹, ìœ ì˜ ì‚¬í•­, ì¶”ì²œ ì‚¬í•­ì„ ë¶„ì„í•˜ì—¬ ì •ë¦¬í•´ ì£¼ì„¸ìš”.

**ìš”êµ¬ ì‚¬í•­:**
1. ì¥ì†Œ, ìŒì‹, ìœ ì˜ ì‚¬í•­, ì¶”ì²œ ì‚¬í•­ ë“± ê°ê°ì˜ ì •ë³´ë¥¼ ì„¸ë¶€ì ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
2. ë§Œì•½ í•´ë‹¹ ì¥ì†Œì—ì„œ ë¨¹ì€ ìŒì‹, ìœ ì˜ ì‚¬í•­, ì¶”ì²œ ì‚¬í•­ì´ ì—†ë‹¤ë©´ ì‘ì„±í•˜ì§€ ì•Šê³  ë„˜ì–´ê°€ë„ ë©ë‹ˆë‹¤.
3. ë°©ë¬¸í•œ ì¥ì†Œê°€ ì—†ê±°ë‚˜ ìœ ì˜ ì‚¬í•­ë§Œ ìˆì„ ë•Œ, ìœ ì˜ ì‚¬í•­ ì„¹ì…˜ì— ëª¨ì•„ì£¼ì„¸ìš”.
4. ì¶”ì²œ ì‚¬í•­ë§Œ ìˆëŠ” ê²ƒë“¤ì€ ì¶”ì²œ ì‚¬í•­ ì„¹ì…˜ì— ëª¨ì•„ì£¼ì„¸ìš”.
5. ê°€ëŠ¥í•œ ì¥ì†Œ ì´ë¦„ì„ ì•Œê³  ìˆë‹¤ë©´ ì‹¤ì œ ì£¼ì†Œë¥¼ í¬í•¨í•´ ì£¼ì„¸ìš”.
6. ì¥ì†Œ ì„¤ëª…ì€ ë°˜ë“œì‹œ ìœ íŠœë²„ê°€ ì–¸ê¸‰í•œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”. ìœ íŠœë²„ì˜ ì‹¤ì œ ê²½í—˜ê³¼ í‰ê°€ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
**ê²°ê³¼ í˜•ì‹:**

ê²°ê³¼ëŠ” ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”
ì•„ë˜ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤. 

ë°©ë¬¸í•œ ì¥ì†Œ: ìŠ¤ë¯¸ë‹¤ íƒ€ì›Œ (ì£¼ì†Œ) íƒ€ì„ìŠ¤íƒ¬í”„: [HH:MM:SS]
- ì¥ì†Œì„¤ëª…: [ìœ íŠœë²„ì˜ ì„¤ëª…] ë„ì¿„ ìŠ¤ì¹´ì´íŠ¸ë¦¬ë¥¼ ëŒ€í‘œí•˜ëŠ” ëœë“œë§ˆí¬ë¡œ, ì „ë§ëŒ€ì—ì„œ ë„ì¿„ ì‹œë‚´ë¥¼ í•œëˆˆì— ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìœ íŠœë²„ê°€ ë°©ë¬¸í–ˆì„ ë•ŒëŠ” ë‚ ì”¨ê°€ ì¢‹ì•„ì„œ í›„ì§€ì‚°ê¹Œì§€ ë³´ì˜€ê³ , ì•¼ê²½ì´ íŠ¹íˆ ì•„ë¦„ë‹¤ì› ë‹¤ê³  í•©ë‹ˆë‹¤.
- ë¨¹ì€ ìŒì‹: ë¼ë©˜ ì´ì¹˜ë€
    - ì„¤ëª…: ì§„í•œ êµ­ë¬¼ê³¼ ì«„ê¹ƒí•œ ë©´ë°œë¡œ ìœ ëª…í•œ ë¼ë©˜ ì²´ì¸ì ìœ¼ë¡œ, ê°œì¸ì‹¤ì—ì„œ í¸ì•ˆí•˜ê²Œ ì‹ì‚¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ìœ ì˜ ì‚¬í•­: í˜¼ì¡í•œ ì‹œê°„ëŒ€ í”¼í•˜ê¸°
    - ì„¤ëª…: ê´€ê´‘ì§€ ì£¼ë³€ì€ íŠ¹íˆ ì£¼ë§ê³¼ íœ´ì¼ì— ë§¤ìš° í˜¼ì¡í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ê°€ëŠ¥í•œ í‰ì¼ì´ë‚˜ ì´ë¥¸ ì‹œê°„ì— ë°©ë¬¸í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
- ì¶”ì²œ ì‚¬í•­: ìŠ¤ì¹´ì´ íŠ¸ë¦¬ ì „ë§ëŒ€ ë°©ë¬¸
    - ì„¤ëª…: ë„ì¿„ì˜ ì•„ë¦„ë‹¤ìš´ ì•¼ê²½ì„ ê°ìƒí•  ìˆ˜ ìˆìœ¼ë©°, ì‚¬ì§„ ì´¬ì˜ í•˜ê¸°ì— ìµœì ì˜ ì¥ì†Œì…ë‹ˆë‹¤.

ë°©ë¬¸í•œ ì¥ì†Œ: ìœ ë‹ˆë²„ì…œ ìŠ¤íŠœë””ì˜¤ ì¼ë³¸ (ì£¼ì†Œ) íƒ€ì„ìŠ¤íƒ¬í”„: [HH:MM:SS]
- ì¥ì†Œì„¤ëª…: [ìœ íŠœë²„ì˜ ì„¤ëª…] ìœ íŠœë²„ê°€ ë°©ë¬¸í–ˆì„ ë•ŒëŠ” í‰ì¼ì„ì—ë„ ì‚¬ëŒì´ ë§ì•˜ì§€ë§Œ, ì‹±ê¸€ë¼ì´ë”ë¥¼ ì´ìš©í•´ì„œ ëŒ€ê¸° ì‹œê°„ì„ ë§ì´ ì¤„ì¼ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. íŠ¹íˆ í•´ë¦¬í¬í„° êµ¬ì—­ì˜ ë¶„ìœ„ê¸°ê°€ ì‹¤ì œ ì˜í™”ì˜ í•œ ì¥ë©´ì— ë“¤ì–´ì˜¨ ê²ƒ ê°™ì•˜ê³ , ë²„í„°ë§¥ì£¼ë„ ë§›ìˆì—ˆë‹¤ê³  í•©ë‹ˆë‹¤.
- ìœ ì˜ ì‚¬í•­: ì§§ì€ ì˜· ì°©ìš© 
    - ì„¤ëª…: íŒ€ë© í”Œë˜ë‹›ì˜ ì¼ë¶€ êµ¬ì—­ì—ì„œëŠ” ë¬¼ì´ ë†’ê³  ê±°ìš¸ì´ ìˆìœ¼ë¯€ë¡œ, ì§§ì€ ì˜·ì„ ì…ëŠ” ê²ƒì´ ì¢‹ë‹¤.

**ìë§‰:**
{transcript_chunk}

ìœ„ ìë§‰ì„ ë°”íƒ•ìœ¼ë¡œ ìœ„ì˜ ìš”êµ¬ ì‚¬í•­ì— ë§ëŠ” ì •ë³´ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”. íŠ¹íˆ ì¥ì†Œ ì„¤ëª…ì€ ë°˜ë“œì‹œ ìœ íŠœë²„ê°€ ì‹¤ì œë¡œ ì–¸ê¸‰í•œ ë‚´ìš©ê³¼ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
"""
        print("\n[generate_prompt] ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ ì¼ë¶€:")
        print(base_prompt[:500])
        return base_prompt

class PlaceService:
    """ì¥ì†Œ ì •ë³´ ì²˜ë¦¬ ì„œë¹„ìŠ¤"""
    
    @staticmethod
    def extract_place_names(summary: str) -> List[str]:
        """ìš”ì•½ í…ìŠ¤íŠ¸ì—ì„œ ì¥ì†Œ ì´ë¦„ì„ ì¶”ì¶œ"""
        place_names = []
        lines = summary.split("\n")
        
        for line in lines:
            if "ì¥ì†Œì„¤ëª…:" in line or "ë°©ë¬¸í•œ ì¥ì†Œ:" in line:
                try:
                    # "ì¥ì†Œì„¤ëª…:" ë˜ëŠ” "ë°©ë¬¸í•œ ì¥ì†Œ:" ì´í›„ì˜ í…ìŠ¤íŠ¸ì—ì„œ ì¥ì†Œ ì´ë¦„ ì¶”ì¶œ
                    place_info = line.split(":", 1)[1].strip()
                    # ê´„í˜¸ê°€ ìˆëŠ” ê²½ìš° ê´„í˜¸ ì•ì˜ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
                    place_name = place_info.split("(")[0].strip()
                    if place_name and place_name not in place_names:
                        place_names.append(place_name)
                except Exception as e:
                    print(f"ì¥ì†Œ ì´ë¦„ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    continue
        
        print(f"ì¶”ì¶œëœ ì¥ì†Œ ëª©ë¡: {place_names}")
        return place_names

    @staticmethod
    def search_place_details(place_name: str) -> Dict[str, Any]:
        """Google Places APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì¥ì†Œ ì •ë³´ë¥¼ ê²€ìƒ‰"""
        try:
            gmaps = googlemaps.Client(key=os.getenv("GOOGLE_PLACES_API_KEY"))
            
            # ì¥ì†Œ ê²€ìƒ‰
            places_result = gmaps.places(place_name)
            
            if not places_result['results']:
                print(f"[search_place_details] ì¥ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {place_name}")
                return None
                
            place = places_result['results'][0]
            place_id = place['place_id']
            
            # ìƒì„¸ ì •ë³´ ê²€ìƒ‰
            details_result = gmaps.place(place_id, language='ko')
            if not details_result.get('result'):
                return None
                
            details = details_result['result']
            
            # ë¦¬ë·° ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            reviews = details.get('reviews', [])
            best_review = reviews[0]['text'] if reviews else None
            
            # ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ìƒì„±
            return {
                'name': details.get('name', ''),
                'formatted_address': details.get('formatted_address', ''),
                'rating': details.get('rating'),
                'formatted_phone_number': details.get('formatted_phone_number', ''),
                'website': details.get('website', ''),
                'price_level': details.get('price_level'),
                'opening_hours': details.get('opening_hours', {}).get('weekday_text', []),
                'photos': details.get('photos', []),
                'best_review': best_review
            }
            
        except Exception as e:
            print(f"[search_place_details] ì¥ì†Œ ì •ë³´ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({place_name}): {str(e)}")
            return None

    @staticmethod
    def get_place_photo_google(place_name: str) -> str:
        """Google Places APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì¥ì†Œ ì‚¬ì§„ URLì„ ê°€ì ¸ì˜´"""
        try:
            gmaps = googlemaps.Client(key=os.getenv("GOOGLE_PLACES_API_KEY"))
            places_result = gmaps.places(place_name)
            
            if not places_result['results']:
                print(f"[get_place_photo_google] ì‚¬ì§„ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {place_name}")
                return None
                
            place = places_result['results'][0]
            if not place.get('photos'):
                return None
                
            photo_reference = place['photos'][0]['photo_reference']
            photo_url = f"https://maps.googleapis.com/maps/api/place/photo?maxwidth=400&photoreference={photo_reference}&key={os.getenv('GOOGLE_PLACES_API_KEY')}"
            
            print(f"[get_place_photo_google] ì‚¬ì§„ URL ìƒì„± ì™„ë£Œ: {photo_url}")
            return photo_url
            
        except Exception as e:
            print(f"[get_place_photo_google] ì‚¬ì§„ URL ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None
